name: model-quantize

permissions:
  contents: write
  actions: read
  id-token: write

defaults:
  run:
    shell: bash

on:
  workflow_dispatch:
    inputs:
      huggingface_repository:
        description: "HuggingFace Repository"
        required: true
        type: string
        default: ""
      model_convert_type:
        description: "Model Convert Type"
        required: true
        type: string
        default: "F16"
      model_quantize_types:
        description: "Model Quantize Types"
        required: true
        type: string
        default: "Q4_K_M,Q5_K_M"
      model_repository:
        description: "Model Repository"
        required: true
        type: string
        default: ""
      model_name:
        description: "Model Name"
        required: true
        type: string
        default: ""
      model_tag:
        description: "Model Tag"
        required: true
        type: string
        default: ""
      model_usage:
        description: "Model Usage"
        required: true
        type: string
        default: "text-to-text"

jobs:
  convert:
    runs-on: ubuntu-22.04
    outputs:
      model_suffix: ${{ steps.prepare.outputs.model_suffix }}
      matrix: ${{ steps.prepare.outputs.matrix }}
    steps:
      - name: Maximize Docker Build Space
        uses: gpustack/gguf-packer-go/.github/actions/maximize-docker-build-space@main
        with:
          root-reserve-mb: 1024
          temp-reserve-mb: 1024
          swap-size-mb: 1024
          deep-clean: true
      - name: Setup Buildx
        uses: docker/setup-buildx-action@v3
        with:
          driver-opts: |
            image=thxcode/buildkit:v0.15.1-git-lfs
      - name: Login DockerHub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.CI_DOCKERHUB_USERNAME }}
          password: ${{ secrets.CI_DOCKERHUB_PASSWORD }}
      - name: Prepare
        id: prepare
        env:
          HF_TOKEN: ${{ secrets.CI_HUGGINGFACE_TOKEN }}
          CONVERT_TYPE: ${{ github.event.inputs.model_convert_type }}
        run: |
          #!/usr/bin/env bash
          
          echo "Get Dockerfile"
          MODEL_VENDOR="$(echo "${{ github.event.inputs.huggingface_repository }}" | cut -d'/' -f1)"
          MODEL_NAME="$(echo "${{ github.event.inputs.huggingface_repository }}" | cut -d'/' -f2)"
          cat <<EOF > ${{ github.workspace }}/Dockerfile
          # syntax=gpustack/gguf-packer:latest
          FROM       scratch AS model
          ADD        https://gpustack:${HF_TOKEN}@huggingface.co/${{ github.event.inputs.huggingface_repository }}.git ${MODEL_NAME}
          FROM       scratch
          LABEL      gguf.model.from="Hugging Face"
          LABEL      gguf.model.usage="${{ github.event.inputs.model_usage }}"
          LABEL      gguf.model.vendor="${MODEL_VENDOR}"
          CONVERT    --from=model --type=${CONVERT_TYPE} ${MODEL_NAME} ${MODEL_NAME}.${CONVERT_TYPE}.gguf
          CMD        ["-m", "${MODEL_NAME}.${CONVERT_TYPE}.gguf", "-c", "8192", "-np", "4"]
          EOF
          
          echo "Get outputs"
          echo "model_suffix=$(echo "${CONVERT_TYPE}" | tr '[:upper:]' '[:lower:]' | sed 's/_/-/g')" >> "$GITHUB_OUTPUT"
          echo "matrix=$(echo "${{ github.event.inputs.model_quantize_types }}" | tr ',' '\n' | jq -R . | jq -s -c .)" >> "$GITHUB_OUTPUT"
      - name: Package
        uses: docker/build-push-action@v6
        with:
          push: true
          context: ${{ github.workspace }}
          no-cache: true
          tags: |
            "${{ github.event.inputs.model_repository }}/${{ github.event.inputs.model_name }}:${{ github.event.inputs.model_tag }}-${{ steps.prepare.outputs.model_suffix }}"
      - name: Review Space Usage
        run: |
          #!/usr/bin/env bash
          
          df -h

  quantize:
    needs:
      - convert
    runs-on: ubuntu-22.04
    strategy:
      fail-fast: false
      matrix:
        type: ${{ fromJson(needs.convert.outputs.matrix) }}
    steps:
      - name: Maximize Docker Build Space
        uses: gpustack/gguf-packer-go/.github/actions/maximize-docker-build-space@main
        with:
          deep-clean: true
      - name: Setup Buildx
        uses: docker/setup-buildx-action@v3
      - name: Login DockerHub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.CI_DOCKERHUB_USERNAME }}
          password: ${{ secrets.CI_DOCKERHUB_PASSWORD }}
      - name: Prepare
        id: prepare
        env:
          CONVERT_TYPE: ${{ github.event.inputs.model_convert_type }}
          QUANTIZE_TYPE: ${{ matrix.type }}
        run: |
          #!/usr/bin/env bash

          echo "Get Dockerfile"
          MODEL_VENDOR="$(echo "${{ github.event.inputs.huggingface_repository }}" | cut -d'/' -f1)"
          MODEL_NAME="$(echo "${{ github.event.inputs.huggingface_repository }}" | cut -d'/' -f2)"
          QUANTIZE_FROM="${{ github.event.inputs.model_repository }}/${{ github.event.inputs.model_name }}:${{ github.event.inputs.model_tag }}-${{ needs.convert.outputs.model_suffix }}"
          cat <<EOF > ${{ github.workspace }}/Dockerfile
          # syntax=gpustack/gguf-packer:latest
          FROM       scratch
          LABEL      gguf.model.from="Hugging Face"
          LABEL      gguf.model.usage="${{ github.event.inputs.model_usage }}"
          LABEL      gguf.model.vendor="${MODEL_VENDOR}"
          QUANTIZE   --from=${QUANTIZE_FROM} --type=${QUANTIZE_TYPE} ${MODEL_NAME}.${CONVERT_TYPE}.gguf ${MODEL_NAME}.${QUANTIZE_TYPE}.gguf
          CMD        ["-m", "${MODEL_NAME}.${QUANTIZE_TYPE}.gguf", "-c", "8192", "-np", "4"]
          EOF

          echo "Get outputs"
          echo "model_suffix=$(echo "${QUANTIZE_TYPE}" | tr '[:upper:]' '[:lower:]' | sed 's/_/-/g')" >> "$GITHUB_OUTPUT"
      - name: Package
        uses: docker/build-push-action@v6
        with:
          push: true
          context: ${{ github.workspace }}
          no-cache: true
          tags: |
            "${{ github.event.inputs.model_repository }}/${{ github.event.inputs.model_name }}:${{ github.event.inputs.model_tag }}-${{ steps.prepare.outputs.model_suffix }}"
